{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificien Sample Model Upload\n",
    "Here, we demonstrate how to create a machine learning model and upload it so that it may be trained on client devices using federated learning.\n",
    "We create a simple linear regression model below, defined in PyTorch syntax, to predict a single variable 'Y' using another three input variables, which are stored in the vector 'X'. We then upload the model to a backend service called a 'PyGrid' node. Models sent to this PyGrid node will be downloaded by client devices (iPhones, Androids, etc.) and trained on local data. \n",
    "\n",
    "Each time a device or set of devices trains your model, the model stored on the PyGrid node will be updated, to reflect the newly improved model. In our case, we train a perceptron model (a very simple machine learning model) to take in the data `age`, `bodyMassIndex` and `sex` to predict a user's `stepCount`. Once we upload your model, then users of the artificien health app can download and train your model on their **real live Apple Health data**, where your model will learn how to utilize the three input variables (`age`, `bodyMassIndex` and `sex`) to predict the output variable (`stepCount`). \n",
    "\n",
    "As soon as you upload the below tutorial model, you'll find it on [artificien.com](https://artificien.com) on your 'models' page. There, you'll be able to check the model progress and download the newly trained model once training is complete. \n",
    "\n",
    "## Cycles, Accuracy, and Model Progress\n",
    "\n",
    "The model uploaded in this tutorial, for the sake of this demonstration, is configured to train on at minimum 1 device per \"training cycle\" and at maximum 5 devices per training cycle. If more than 1 device but fewer than 5 devices have trained your model within 1 hour, this cycle will be marked complete. Likewise, *as soon as* 5 devices have trained your model, the cycle is complete. In total, this model will train for 5 cycles. \n",
    "\n",
    "As your model trains, devices training the model will send 'updates' to our backend servers indicating how the model should be improved. Once a cycle completes, we average up all of the 'updates' that devices who trained your model sent, and create a new-and-improved model, which incorporates the learnings your model obtained while training on the devices. Then, when another cycle commences, devices will download this new-and-improved model and send information to us on how we can improve *that* model even further as well. This process, where we iteratively update the model at the end of each cycle, continues until we reach `num_cycles`. As your model trains, you'll see its average loss (in this case, the number of steps by which it misses the mark when trying to predict someone's step count) update, and you'll see that its progress % goes up over time.\n",
    "\n",
    "For the machine learning engineers out there - think of `num_cycles` as analagous to `num_epochs`, and min/ max `num_devices` as analagous to `batch_size`. In standard ML, models are updated at end of an epoch, after training on `batch_size` samples. In federated ML, model parameters are updated at the end of a cycle, after training on `num_devices`.\n",
    "\n",
    "Note that, for a real machine learning model, you'd certainly want to train on a lot more than 1-5 devices per cycle, and you might want to have more than 5 cycles.\n",
    "\n",
    "## Please Read: \n",
    "- You cannot save changes made to this tutorial - this file is shared by all Artificien users and cannot be altered. To create your own notebooks (which can be edited and saved), create a new notebook in your root ('/') directory, or make a copy of this notebook and place it in your root directory.\n",
    "\n",
    "- To build models for deployment to actual devices running Artificien partner apps, ensure that your model can train on and make predictions using the provided [sample dataset](../sample_data) corresponding to the type of data you'd like to build on top of. For this tutorial, we ensure that the model indeed works on the health app data before sending it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from artificienlib import syftfunctions as sf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from syft.federated.fl_client import FLClient\n",
    "from syft.federated.fl_job import FLJob\n",
    "from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data\n",
    "For every dataset on [artificien.com](https://artificien.com), we provide a sample dataset to demonstrate to you what the data on user devices will actually look like. Here, we explore the Artificien Dataset. Before we deploy our ML model for training, we'll first make sure it works correctly on the sample dataset. Note that the sample dataset is entirely made-up data - the real data **only** ever exists on user devices, and it **never** goes anywhere else. We keep the user's privacy first and foremost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Weekly Step Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>67173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>105109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>175606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>220145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Body Mass Index  Weekly Step Count\n",
       "0   41    1               43              67173\n",
       "1   47    1                2             113562\n",
       "2  100    1               23             105109\n",
       "3   42    1                8             175606\n",
       "4   89    0                7             220145"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_data = pd.read_csv('../sample_data/Artificien-Health.csv')\n",
    "health_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Labels\n",
    "We want to build a model that uses Age, Sex, and Body Mass Index in order to predict an individual's step count. For this reason, we split up the training features and labels as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Age', 'Sex', 'Body Mass Index']\n",
    "# features = ['Body Mass Index']\n",
    "label_names = ['Weekly Step Count']\n",
    "features = health_data[feature_names]\n",
    "labels = health_data[label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Body Mass Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Body Mass Index\n",
       "0   41    1               43\n",
       "1   47    1                2\n",
       "2  100    1               23\n",
       "3   42    1                8\n",
       "4   89    0                7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Features\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly Step Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weekly Step Count\n",
       "0              67173\n",
       "1             113562\n",
       "2             105109\n",
       "3             175606\n",
       "4             220145"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Labels (only one in this case)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "In order to test our model on the sample data, we'll perform a train test split. We'll save 80% of the sample data for training (X_train, y_train) and 20% of the sample data for testing. We'll alsodefine a standard Torch DataLoader to load in the data. Note that the exact training process we've shown here will *also* occur on the user devices.\n",
    "\n",
    "As explained above, `batch_size` and `num_devices` are analagous in some ways, so we'll set our `batch_size` equal to 5 - the maximum number of devices per cycle we aim to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(features, labels, batch_size):\n",
    "    features = th.tensor(features.values.astype(np.float32)) \n",
    "    labels = th.tensor(labels.values.astype(np.float32))\n",
    "    tensor = th.utils.data.TensorDataset(features, labels)\n",
    "    loader = th.utils.data.DataLoader(dataset=tensor, batch_size=batch_size, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2) # 20% of data retained for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dataloader = get_data_loader(train_features, train_labels, batch_size)\n",
    "test_dataloader = get_data_loader(test_features, test_labels, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model\n",
    "Here, we define our model using standard pytorch model definition. This example is just a simple 3 variable linear classifier. Note that the LinearRegression model does not need the input data nor the labels to be normalized. Other ML models; however, do. This normalization process for other machine learning models will be described in another tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(th.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = th.nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model on the sample data\n",
    "To train the model, we choose a standard mean absolute error (MAE) loss, which means that our loss is in the same units as our labels. In this case, this means that our loss indicates the number of steps by which our model 'missed the mark'. We set our learning rate to 0.01, a standard rate in most ML workflows.\n",
    "\n",
    "We set our `num_epochs` to 5, since, as explained above, the number of cycles is analagous to the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get our model\n",
    "model = LinearRegression(input_size=3, output_size=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "lr = 0.01 # learning rate\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = th.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\" A standard PyTorch training function \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        # y = nn.functional.normalize(y) # model outputs normalized predictions\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "        optimizer.zero_grad() \n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with th.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # y = nn.functional.normalize(y)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(th.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error - Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error - Avg loss: 23192.588203 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error - Avg loss: 22586.672793 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error - Avg loss: 22017.616406 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Test Error - Avg loss: 21480.276680 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Test Error - Avg loss: 20973.369883 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Train it\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss = test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done Training!\n",
    "As you can see, our model improved as it trained. In a real world scenario, you'd likely want a much larger batch size (`num_devices`) and epoch count (`num_cycles`) in order for your model to improve substantially. Nevertheless, we've shown some improvement here, reaching an average weekly step count error of around 20K, and it is clear that the model has begun to determine how the input data predicts the output label (step count). Below, we print the average step count error we obtained, and a 'baseline' metric, which is the average error you would obtain if you were to simply guess that all individuals had the *average* step count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test loss: 20973\n",
      "Test loss obtained by guessing: 75347\n"
     ]
    }
   ],
   "source": [
    "print('Our test loss:', int(test_loss))\n",
    "print('Test loss obtained by guessing:', int(test_labels.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, if we were to train our model with a larger batch size or more epochs (more devices and more cycles), we'd get a better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "train_dataloader = get_data_loader(train_features, train_labels, batch_size)\n",
    "test_dataloader = get_data_loader(test_features, test_labels, batch_size)\n",
    "\n",
    "for t in range(epochs):\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss = test(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test loss: 3563\n",
      "Test loss obtained by guessing: 75347\n"
     ]
    }
   ],
   "source": [
    "print('Our test loss:', int(test_loss))\n",
    "print('Test loss obtained by guessing:', int(test_labels.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning\n",
    "Now that we've built and validated that our model works on the sample data - here comes the easy part. Now, we simply upload our model to artificien's backend servers, to make it available for download and training by client devices. Lets walk you through the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check available datasets\n",
    "Check the datasets that you've purchased access to. Today, we'll use the Artificien Health dataset, which you'll have access to by default. Enter your artificien password bellow so artificien can validate your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = \"artificien1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasets': ['Artificien-Health']}\n"
     ]
    }
   ],
   "source": [
    "sf.get_my_purchased_datasets(password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name your model\n",
    "Next, we name the model. Feel free to name it anything you like, but note that, once you upload a model with a given name and version... you cannot use that name and version again. For every new model you upload, you create a unique (name, version) pair. We do this to keep track of which model is which on (artificien.com)[artificien.com]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"tutorial-model\"\n",
    "version = \"1.0\"\n",
    "dataset = \"Artificien-Health\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Training Plan\n",
    "First, we must choose some dummy X and Y representative of our input and output parameters respectively. Then, we select a learning rate and batch size. Since each user only has a single entry for their BMI/ step count/ etc., the batch size should be set to '1' (each user only has one sample of data). We set the learning rate to 0.01, just as we did in our sample dataset trial run. Likewise, we use mean absolute error as our loss function. We pass all these parameters into artificien's `def_training_plan` function to obtain a federated learning training plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "batch_size = 1 # each user only has a single entry of data\n",
    "X = th.randn(1, 3) # dimensions of the input data (3 features)\n",
    "y = nn.functional.one_hot(th.tensor([1])) # dimensions of the labels (a single number - step count)\n",
    "model_params, training_plan = sf.def_training_plan(model, X, y, batch_size, lr, {\"loss\": sf.mse_with_logits})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining an Averaging Plan\n",
    "Next we define our averaging plan - the way our model averages the results from multiple edge devices. Here, we just use the default averaging plan, which is to take all model updates from any device in equal weight - that is, Device 1 should have just as much input as device 2 when improving the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_plan = sf.def_avg_plan(model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send Model\n",
    "Next, we sent the model to artificien's backend services to be hosted and downloaded by client devices. Here, we are using the features we defined up above - `age`, `bodyMassIndex` and `sex` to predict a the label - `stepCount`... so we make sure to let artificien's servers know that this is the case. If we instead, say, wanted to to predict a person's age using only their `sex` and `stepCount`, we are free to do that as well.\n",
    "\n",
    "Note that we set `min_workers` to 1, `max_workers` to 8, and `num_cyles` to 5.\n",
    "\n",
    "If you happen to be the first person to run this tutorial in a while, you will need to wait a few minutes for the infrastructure to host your model to be created. Otherwise, you'll see that your model is uploaded and made available for training almost instantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Sex', 'Body Mass Index']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weekly Step Count']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host response: {'type': 'model-centric/host-training', 'data': {'status': 'success'}}\n"
     ]
    }
   ],
   "source": [
    "sf.send_model(\n",
    "    \n",
    "    # Model Information\n",
    "    name=name, \n",
    "    dataset_id=dataset, \n",
    "    version=version, \n",
    "    \n",
    "    # Determine what training should look like\n",
    "    min_workers=1,\n",
    "    max_workers=5,\n",
    "    num_cycles=5,\n",
    "\n",
    "\n",
    "    # Set the training and average plans\n",
    "    batch_size=1, \n",
    "    learning_rate=0.2,\n",
    "    model_params=model_params,\n",
    "    features=feature_names, \n",
    "    labels=label_names,\n",
    "    avg_plan=avg_plan,\n",
    "    training_plan=training_plan,\n",
    "    \n",
    "    # Authenticate\n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!\n",
    "If we get the response \"Host response: {'type': 'model-centric/host-training', 'data': {'status': 'success'}}\"\n",
    "back, then our model was successfully uploaded to our backend services, and is now available to be downloaded and trained by client devices. If you navigate to [your models](https://artificien.com/models), you can monitor your model's progress and loss, and download it once it's done.\n",
    "\n",
    "## Learn More\n",
    "To learn more about how to use the artificien library for your own unique models, head to our documentation page at [artificien.com/data_scientist_documentation](https://artificien.com/data_scientist_documentation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
